{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch与MNIST\n",
    "\n",
    "## 说明\n",
    "\n",
    "程序源代码参考：https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "本代码实现最简单的三层神经网络，全是线性层，不含卷积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST数据集\n",
    "\n",
    "MNIST的图像数据是28像素×28像素的灰度图像（1通道），各个像素的取值在0到255之间。每个图像都相应地标有“1”、“2”、“3”等标签\n",
    "\n",
    "## 设定网络结构\n",
    "\n",
    "- 第一个__init__是初始化的参数，包含三个全连接层(fc)。\n",
    "\n",
    "```Python\n",
    "class torch.nn.Linear(in_features, out_features, bias=True)\n",
    "```\n",
    "\n",
    ">fc1采用线性变换层实现，输入样本大小为28\\*28，输出样本大小为50。\n",
    ">\n",
    ">fc2采用线性变换层实现，输入样本大小为50，输出样本大小为100。\n",
    ">\n",
    ">fc3采用线性变换层实现，输入样本大小为100，输出样本大小为10，由于这是最后一层（不算输出层），所以10就是10个类别。\n",
    ">\n",
    ">说明：其中的50和100可以自己设置。\n",
    "\n",
    "- 第二个函数forward指的是前向传播。\n",
    "\n",
    "  前向传播指明了传播方向，即从fc1依次经过fc2、fc3，最后经过log_softmax输出结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=28*28, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载MNIST集\n",
    "\n",
    "MNIST下载完毕后会有4个文件，分别是：\n",
    "\n",
    ">train-images.idx3-ubyte 训练集X\n",
    ">\n",
    ">train-labels.idx1-ubyte 训练集y\n",
    ">\n",
    ">t10k-images.idx3-ubyte 测试集X\n",
    ">\n",
    ">t10k-labels.idx1-ubyte 测试集y\n",
    "\n",
    "Pytorch的torchvision已经有封装好的MNIST数据集类，我们在这里直接使用。\n",
    "\n",
    "```Python\n",
    "from torchvision import datasets\n",
    "datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)\n",
    "```\n",
    "\n",
    "其中：\n",
    "- root：指的是下载路径，这里人工指定为'./MNIST_data'\n",
    "- train：True就是训练集，False就是测试集\n",
    "- download：True指的是如果没有数据集则下载，如果有就不下载。\n",
    "- transform：指的是数据变换增强，比如翻转，拉伸等等。在这一步我们先检查数据，不使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./MNIST_data/MNIST', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./MNIST_data/MNIST', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们一起来康康这些数据集有多大。\n",
    "\n",
    "可以看出训练集有60000条数据而测试集有10000条数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist_trainset))\n",
    "print(len(mnist_testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查一下mnist_trainset的第一个元素是什么东西？\n",
    "\n",
    "结果表明，这是一个PIL.Image，而且其类型是tuple类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x7F18500DB080>, tensor(5))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist_trainset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 show() 函数来展示图像，并且康康这个图像对应的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该图片的标签是：  tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image_zero, test_target_zero = mnist_testset[0]\n",
    "plt.imshow(test_image_zero, cmap ='gray')  # 灰度图像\n",
    "print(\"该图片的标签是： \",test_target_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集抽象化\n",
    "\n",
    "上面的mnist_trainset和mnist_testset只是读取了相关数据，但是为了让Pytorch能够使用这些数据，还需要使用数据加载起将其抽象化。\n",
    "\n",
    "数据加载器如下：\n",
    "\n",
    "```Python\n",
    "class torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, num_workers=0, collate_fn=<function default_collate>, pin_memory=False, drop_last=False)\n",
    "```\n",
    "- dataset (Dataset)：加载数据的数据集。\n",
    "- batch_size (int, optional)： 每个batch加载多少个样本(默认: 1)。\n",
    "- shuffle (bool, optional)：设置为True时会在每个epoch重新打乱数据(默认: False).\n",
    "- sampler (Sampler, optional)：定义从数据集中提取样本的策略。如果指定，则忽略shuffle参数。\n",
    "- num_workers (int, optional)：用多少个子进程加载数据。0表示数据将在主进程中加载(默认: 0)\n",
    "- collate_fn (callable, optional)\n",
    "- pin_memory (bool, optional)\n",
    "- drop_last (bool, optional)：如果数据集大小不能被batch size整除，则设置为True后可删除最后一个不完整的batch。如果设为False并且数据集的大小不能被batch size整除，则最后一个batch将更小。(默认: False)\n",
    "\n",
    "现在重新读取数据，因为要放入网络计算，我们是不能使用PIL.image格式的，需要转换为Tensor形式。\n",
    "需要说明的是，在transforms中我们使用了ToTensor和正规化的方法，其中：\n",
    "- Compose：是将多个transform组合起来使用的方法\n",
    "- ToTensor：这里把一个取值范围是[0,255]的PIL.Image转换成形状为[C,H,W]，取值范围是[0,1.0]的torch.FloadTensor\n",
    "- Normalize：给定均值mean和方差std，这里会把Tensor正则化。\n",
    "\n",
    "**注意：针对PIL图像必须ToTensor，否则后面不能运算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./MNIST_data/MNIST', train=True, download=True, transform=data_tf)\n",
    "mnist_testset = datasets.MNIST(root='./MNIST_data/MNIST', train=False, download=True, transform=data_tf)\n",
    "\n",
    "train_loader = DataLoader(mnist_trainset, batch_size=1000, shuffle=True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络\n",
    "\n",
    "在检查完毕数据集以后，我们要开始网络的训练了。之前在第一部分已经建立好了一个简单的三层神经网络。\n",
    "\n",
    "### 初始化网络\n",
    "\n",
    "前面我们已经建立好网络了，在这里将网络（参数等）初始化，顺便判断CUDA是否可用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "# 初始化网络\n",
    "net = Net()\n",
    "if torch.cuda.is_available():  # 如果GPU可以使用\n",
    "    net = net.cuda()\n",
    "    print(\"CUDA is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置优化器\n",
    "\n",
    "优化器的种类很多，包括但不限于：\n",
    "\n",
    "- SGD：随机梯度下降\n",
    "- Momentum：带动量的梯度下降\n",
    "- AdaGrad：带学习率衰减的梯度下降\n",
    "- Adam：结合了动量和学习率衰减的梯度下降\n",
    "\n",
    "这里我们使用最简单的SGD，也就是随机梯度下降,用法如下：\n",
    "\n",
    "```Python\n",
    "class torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "```\n",
    "- params (iterable) – 待优化参数的iterable或者是定义了参数组的dict\n",
    "- lr (float) – 学习率\n",
    "- momentum (float, 可选) – 动量因子（默认：0）\n",
    "- weight_decay (float, 可选) – 权重衰减（L2惩罚）（默认：0）\n",
    "- dampening (float, 可选) – 动量的抑制因子（默认：0）\n",
    "- nesterov (bool, 可选) – 使用Nesterov动量（默认：False）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)  # 传入 net 的所有参数, 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置损失函数\n",
    "\n",
    "损失函数的计算也有很多种，这里我们使用交叉熵作为我们的损失函数计算方法，用法如下：\n",
    "\n",
    "```Python\n",
    "class torch.nn.CrossEntropyLoss(weight=None, size_average=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练\n",
    "\n",
    "需要说明的几点\n",
    "\n",
    "1. 第一个 if 判断的是CUDA是否可用，这里其实没有使用CUDA，可以无视。\n",
    "2. optimizer.step() 用于更新参数，大多数优化器都实现了step()函数\n",
    "3. img刚刚读取的时候，其 size 为 torch.Size([1000, 1, 28, 28])，是一个四维数组，需要变换才可使用。\n",
    ">为什么要变换后使用？\n",
    ">\n",
    ">因为这里我们用的是Linear层，只能接受1维度数组。如果使用卷积层，就可以接受二维图像了。\n",
    "4. 初始化网络后才能设置优化器和损失函数，不能先设置损失函数和优化器再初始化网络。\n",
    "5. 每次反向传播之前必须先把梯度归零。\n",
    "6. torch.nn.Module.train():就是训练模式,在此模式中会启用Dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_ndx: 0, loss: 2.295\n",
      "epoch: 0, batch_ndx: 10, loss: 2.136\n",
      "epoch: 0, batch_ndx: 20, loss: 1.997\n",
      "epoch: 0, batch_ndx: 30, loss: 1.856\n",
      "epoch: 0, batch_ndx: 40, loss: 1.734\n",
      "epoch: 0, batch_ndx: 50, loss: 1.6\n",
      "epoch: 1, batch_ndx: 0, loss: 1.493\n",
      "epoch: 1, batch_ndx: 10, loss: 1.386\n",
      "epoch: 1, batch_ndx: 20, loss: 1.256\n",
      "epoch: 1, batch_ndx: 30, loss: 1.157\n",
      "epoch: 1, batch_ndx: 40, loss: 1.118\n",
      "epoch: 1, batch_ndx: 50, loss: 0.9991\n",
      "epoch: 2, batch_ndx: 0, loss: 1.025\n",
      "epoch: 2, batch_ndx: 10, loss: 0.9333\n",
      "epoch: 2, batch_ndx: 20, loss: 0.8374\n",
      "epoch: 2, batch_ndx: 30, loss: 0.8372\n",
      "epoch: 2, batch_ndx: 40, loss: 0.7532\n",
      "epoch: 2, batch_ndx: 50, loss: 0.7075\n",
      "epoch: 3, batch_ndx: 0, loss: 0.7214\n",
      "epoch: 3, batch_ndx: 10, loss: 0.6841\n",
      "epoch: 3, batch_ndx: 20, loss: 0.6959\n",
      "epoch: 3, batch_ndx: 30, loss: 0.6821\n",
      "epoch: 3, batch_ndx: 40, loss: 0.6326\n",
      "epoch: 3, batch_ndx: 50, loss: 0.5712\n",
      "epoch: 4, batch_ndx: 0, loss: 0.6039\n",
      "epoch: 4, batch_ndx: 10, loss: 0.6247\n",
      "epoch: 4, batch_ndx: 20, loss: 0.5587\n",
      "epoch: 4, batch_ndx: 30, loss: 0.5648\n",
      "epoch: 4, batch_ndx: 40, loss: 0.5467\n",
      "epoch: 4, batch_ndx: 50, loss: 0.5601\n"
     ]
    }
   ],
   "source": [
    "# 5个epoch\n",
    "net.train()  # 启用train模式\n",
    "for epoch in range(5):\n",
    "    for batch_ndx, data in enumerate(train_loader):  # 按照一个batch = 1000来抽取数据\n",
    "        img, label = data\n",
    "        # print(img.size())\n",
    "        img = img.view(img.size(0), -1)  # 展开为一维数组\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            # print(\"使用CUDA训练\")\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # 前向传播\n",
    "        output = net(img)\n",
    "        loss = loss_func(output, label)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()  # 梯度归零\n",
    "        loss.backward()  # 损失函数反向传播\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_ndx%10 == 0:\n",
    "            print('epoch: {}, batch_ndx: {}, loss: {:.4}'.format(epoch, batch_ndx, loss.data.item()))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始测试\n",
    "\n",
    "需要说明几点：\n",
    "1. torch.nn.Module.eval()：将模型变为评估模式，此模式关闭Dropour()\n",
    "\n",
    ">效果等同于 torch.nn.Module.train(False)\n",
    "\n",
    "2. label.size(0)这里是一个batch的大小，就是1000。\n",
    "3. eval_loss 就等于每一个batch的loss乘以1000再累加。最后再把累加起来的loss，除以测试集总数，就是预计的loss。\n",
    "4. eval_acc 同理。先计算每个batch中pred和label相等的数量（正确数量），然后累加，最后除以测试集总数，就是实际的acc。\n",
    "5. 注意：loss.data.item()才是真正的损失值，如果直接使用loss，返回的实际上是一个loss图，会导致显存爆炸。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Test Loss: 0.501702, Acc: 0.874500\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "eval_loss = 0\n",
    "eval_acc = 0\n",
    "\n",
    "# 对测试集进行测试\n",
    "for batch_ndx, data in enumerate(test_loader):\n",
    "    # 获得img(手写图片)，label标签（手写图片对应数字）\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "    \n",
    "    #  向前传播，获得out结果和损失函数\n",
    "    output = net(img)\n",
    "    loss = loss_func(output, label)  # 交叉熵\n",
    "    \n",
    "    # 损失函数乘标签大小累计\n",
    "    eval_loss += loss.data.item()*label.size(0)  # 每个计算一次损失？\n",
    "    # 在10维数据中，获得最大的预测值（即预测数）\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # 判断是否与真实结果相同\n",
    "    num_correct = (pred == label).sum()\n",
    "    \n",
    "    # 累计真实结果\n",
    "    eval_acc += num_correct.item()\n",
    "\n",
    "print(label.size(0))\n",
    "# 输出评估结果    \n",
    "print('Test Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "    eval_loss / (len(mnist_testset)),\n",
    "    eval_acc / (len(mnist_testset))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5187490582466125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制图像（临时）\n",
    "\n",
    "### Visdom安装\n",
    "\n",
    "https://github.com/facebookresearch/visdom\n",
    "\n",
    "```Shell\n",
    "pip install visdom\n",
    "```\n",
    "\n",
    "### Visdom启动\n",
    "\n",
    "打开Powershell，运行如下命令，然后在浏览器中访问：http://localhost:8097\n",
    "\n",
    "```Shell\n",
    "visdom\n",
    "```\n",
    "\n",
    "然后运行如下代码，如果visdom窗口有所显示，则说明成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_378f6192562c1a'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visdom hello world\n",
    "import visdom\n",
    "import numpy as np\n",
    "vis = visdom.Visdom()\n",
    "vis.text('Hello, World!')\n",
    "tr_loss=list(range(100))\n",
    "viz.line(Y=np.array(tr_loss), opts=dict(showlegend=True))\n",
    "vis.image(np.ones((3, 10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
